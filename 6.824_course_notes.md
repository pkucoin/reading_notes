# 课程主要议题

抽象使分布式应用程序本身可以不关注如何做分布式，这样的抽象包括
- 存储
- 通信
- 计算
这些抽象中，一些问题反复出现。

## 实现
- RPC，线程，并发控制

## 性能
- 理想状态：完全可伸缩的吞吐，N台服务器带来N倍的吞吐
- N变大后，可伸缩性很困难
  - 负载不均衡
  - 非并行的代码
  - 共享资源的瓶颈，例如网络的限制
- 一些性能问题并不能通过伸缩性来轻易解决

## 容错
- 集群规模增长导致总会有机器挂掉，希望应用程序本身可以不关注这些错误
- 可用性：即使有错误发生，应用仍然可以继续
- 基本思路：复制

## 一致性
- 通用架构需要良好定义的行为
  - Get(k)返回最近一次Put(k, v)的v
- 一致性很难
  - 服务器的复制很难保持一致
  - 客户端和服务器可能在任何时刻崩溃
  - 网络可能导致特定服务器无法访问，有“裂脑”风险
- 一致性和性能是矛盾的


# MapReduce
## 概述
- 背景：大数据集需要的计算时间很长
- 目标：不是分布式专家的程序员也可以在大集群上通过分割数据处理过程来获得不错的效率
- 自定义的相对简单的串行处理的Map和Reduce函数
- 隐藏分布式的细节，在大集群上处理海量输入

## 抽象过程
- 输入被分成M个文件，Map按行产生键值对，Reduce按相同key的列来处理键值对
- MR对每一个输入文件调用Map产生键值对(k2, v2)的集合，收集所有键值对，并对所有key为k2的键值对将所有的值传给Reduce
- map(k1, v1) -> list(k2, v2)
- reduce(k2, list(v2)) -> list(k2, v3)
- 隐藏了大量痛点：任务分配与追踪、数据转移、容错与恢复
- 优秀的可扩展性
- 可能限制性能的点：网络带宽

## 详细过程
- Master分配任务给worker，记录中间输出的位置
- M个Map任务，R个Reduce任务
- 输入输出均存储在GFS上，每一份输入文件有三份副本
- 所有的服务器都同时运行MR和GFS的worker
  - 针对慢速网络影响的设计
- Map任务总数比worker数大很多
  - 针对负载均衡的设计
- Master首先给每一个worker分配一个Map任务，完成后继续分配新的任务
- Map worker将输出的中间结果根据key值hash到本地的R个文件上
- 等所有的Map任务完成后才会开始Reduce任务
- Master告知Reduce worker中间输出数据在Map worker上的位置
- Reduce worker将最终输出结构写到GFS中（一个Reduce任务对应一个输出文件）

## 容错设计

### 总体思路：仅重跑出错的任务
- 要求Map和Reduce满足pure function，即
  - 在前后任务间不保存状态
  -  除了期望的输入输出之外不读写其他文件
  -  任务只和Master通信，任务间不进行通信
- 满足上述要求后，仅仅重跑失败的任务也保证获得和正常运行一样的输出
- 这样的要求是MR的一个主要局限所在，但同样带来了简洁性的好处

### 具体实现
- Map worker挂了
  - master失去worker心跳后，通过输入的其他副本在其他worker上重跑Map
  - 一些Reduce worker
- Reduce worker挂了
  - 如果尚未完成，master将任务分配给其他worker
- 在输出结果的时候Reduce worker挂了
  - Master在其他worker上重跑Reduce
  - GFS的重命名是原子的，可以防止输出在完成之前变为可见
- 其他问题
  - 同一个Map任务被两个worker跑：只有一个中间结果会被看到
  - 同一个Reduce任务被两个worker跑：只有一个输出结果会被看到
  - 一个很慢的worker：master会将跑的最慢的未完成任务再分配一次
  - 因为硬件或软件故障，输出是错的：MR假定硬件或软件出错则停止
  - master挂了：从检查点恢复，或者放弃
  
  # 分布式一致性: Raft协议
- 主议题：使用复制状态机的容错服务
- 核心问题：如何避免“裂脑”
  - 两个复制服务器A, B，客户端可以与A通信，不能和B通信，客户端可以在只有A可以通信的情况正常工作吗？
  - 如果原因是B确实挂了，那么客户端只能和A通信继续工作（不然就不容错了）
  - 如果B没挂，但是因为网络原因客户端无法与B通信，那么就有裂脑风险
  - 例如，client1与A通信，client2与B通信。c1: put(k1, v1) c2 : put(k1, v2) c1 : get(k1) -> v1
  - 问题在于无法区分不能通信究竟是因为挂了还是网络问题
- 期望的基于状态机的复制方案应该满足
  - 单点故障下服务仍然可用
  - 可以应对裂脑问题
  - 故障太多时等待修复，然后可以恢复服务
- 基本思路：多数投票
  - 2f+1台服务器可以容忍f个故障
  - 必须得到多数服务器（至少f+1）一致通过（蛤）才可以继续
- 实现
  - 20世纪90年代：Paxos和View-Stamped replication
  - 现代：Raft

## Raft总览
- 服务器的Raft层选举一个leader，客户端将rpc命令发送给leader的kv层
- kv层并不直接回应，而是将命令转发给leader的Raft层
- leader的Raft层将客户端命令发送给所有follower
  - 通过AppendEntries rpc，每一个follower将命令添加到本地log（尚未commit），并通知leader已添加
- 当leader发现多数follower已经完成添加后，请求被commit
  - 此时已经确保命令不会被遗忘
- 将请求真正作用于kv状态机，并返回结果给客户端
- log的作用
  - 对命令编号，来保证执行顺序的一致，以及所有follower的log完全相同
  - 存储命令，以便在follower丢失时重发，并进行持久化
- Raft设计的主要部分：leader选举、log一致

## leader选举
- leader的作用：确保所有replicas以相同顺序执行相同命令
- 使用任期对leader序列进行编号
  - 新的leader对应一个新的任期，一个任期至多有一个leader（可能没有）
  - 每次选举对应一个特定任期，一个任期内只有一次成功的选举
  - 任期编号帮助服务器follow最新的leader
- 开始选举的时机
  - AppendEntries rpc同时也起着心跳作用，leader会周期性地发送给follower
  - 如果follower接受AppendEntries超时，它们认为leader挂了并开始一场选举
  - follower将本地的当前任期加1，变为candidate，开始选举
  - 选举可能是不必要的（虽然慢但是安全），选举开始时旧leader可能没挂并仍认为它是leader
- candidate的三种结局
  - 获得多数投票，转变为leader
    - 本地计票，不能应对拜占庭式故障
  - 未获得多数投票，同时接收到了新leader
    - 通过AppendEntries rpc，接受新leader，转变为follower
  - 未获得多数投票，也没有接收到新leader
    - 可能处于一个少数网络分区中，选举超时后开始一次新的选举（仍然是candidate）
    - 在这种少数网络分区中可能会一直增加任期，但不能成为leader所以无法添加log
    - 当网络恢复时，要么多数网络分区中的log更长（不能赢得选举），要么log一样长（赢得选举，无害）
- 确保一个任期内至多一个leader
  - 每个server对于一个任期至多投出一票
  - 无论是否存在网络故障或server故障，一个任期内都只可能有一个server赢得超过半数的投票
  - 选举可以在一些server挂掉的情况下完成
- 新leader成立的方式
  - 当获得超过半数的票时，立即发送AppendEntries的心跳rpc，这同时会终止新的选举
- 选举失败
  - 可能因为可达的server不到半数，也可能多个candidate瓜分了选票，无人达到半数
  - 经过一个timeout之后，进行新的一次选举。更高的任期可以使得较低任期的candidate退出
  - 通过让每个server选择一个随机的timeout，打破了同时开始的选举一直进行下去的可能
  - timeout至少是心跳间隔的若干倍，随机的部分要足够让一个candidate在下一个选举开始前完成选举，同时也要足够进行若干次的重试
